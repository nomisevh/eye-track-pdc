{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from yaml import load as load_yaml, FullLoader\n",
    "\n",
    "from dataset import KIDataset, train_test_split_stratified\n",
    "from models.inceptiontime import LitInceptionTimeModel\n",
    "from models.transformer import TransformerClassifier, LitTimeSeriesClassifier\n",
    "from processor.processor import Leif\n",
    "from utils.const import SEED\n",
    "from utils.data import binarize\n",
    "from utils.misc import set_random_state\n",
    "from utils.path import config_path, log_path, checkpoint_path\n",
    "\n",
    "set_random_state(SEED)\n",
    "!conda activate eyetrackpdc\n",
    "\n",
    "# Data parameters\n",
    "BINARY_CLF = True\n",
    "\n",
    "# Dataloader Parameters\n",
    "BATCH_SIZE_SEGMENTS = 128\n",
    "BATCH_SIZE_TRIALS = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Configs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(config_path.joinpath('leif.yaml'), 'r') as reader:\n",
    "    processor_config = load_yaml(reader, Loader=FullLoader)\n",
    "with open(config_path.joinpath('transformer.yaml')) as reader:\n",
    "    transformer_config = load_yaml(reader, Loader=FullLoader)\n",
    "with open(config_path.joinpath('inception.yaml')) as reader:\n",
    "    inception_config = load_yaml(reader, Loader=FullLoader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize the processor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Configure processor\n",
    "processor = Leif(processor_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Data (segments)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset from C:\\Users\\hejpa\\Documents\\GitHub\\eye-track-pdc\\data\\ki\\tmp\\ki-dataset-seg-train\n",
      "loaded dataset from C:\\Users\\hejpa\\Documents\\GitHub\\eye-track-pdc\\data\\ki\\tmp\\ki-dataset-seg-test\n"
     ]
    }
   ],
   "source": [
    "# Initialize Datasets\n",
    "train_val_ds = KIDataset(data_processor=processor, train=True, bundle_as_trials=False, use_triplets=True)\n",
    "train_ds, val_ds = train_test_split_stratified(train_val_ds, test_size=0.2)\n",
    "test_ds = KIDataset(data_processor=processor, train=False, bundle_as_trials=False, use_triplets=True)\n",
    "\n",
    "# Binarize dataset after split to make sure split is stratified w.r.t all three classes\n",
    "if BINARY_CLF:\n",
    "    for ds in [train_ds, val_ds, test_ds]:\n",
    "        binarize(ds)\n",
    "\n",
    "# Initialize Dataloaders\n",
    "train_dl = DataLoader(train_ds,\n",
    "                      batch_size=BATCH_SIZE_SEGMENTS,\n",
    "                      sampler=ImbalancedDatasetSampler(train_ds, callback_get_label=lambda item: item.y))\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE_SEGMENTS)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE_SEGMENTS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Initialize Rocket\n",
    "inception_time = LitInceptionTimeModel(**inception_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train InceptionTime using Triplet Loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Trainer(accelerator='auto',\n",
    "                  max_epochs=200,\n",
    "                  logger=TensorBoardLogger(save_dir=log_path),\n",
    "                  callbacks=[LearningRateMonitor(),\n",
    "                             ModelCheckpoint(dirpath=checkpoint_path, monitor='val_loss', every_n_epochs=1)],\n",
    "                  log_every_n_steps=1)\n",
    "trainer.fit(inception_time, train_dl, val_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Data (trials)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset from C:\\Users\\hejpa\\Documents\\GitHub\\eye-track-pdc\\data\\ki\\tmp\\ki-dataset-trial-train\n",
      "loaded dataset from C:\\Users\\hejpa\\Documents\\GitHub\\eye-track-pdc\\data\\ki\\tmp\\ki-dataset-trial-test\n"
     ]
    }
   ],
   "source": [
    "# Reset seed to ensure the same data split\n",
    "set_random_state(SEED)\n",
    "\n",
    "# Initialize Datasets\n",
    "train_val_ds = KIDataset(data_processor=processor, train=True, bundle_as_trials=True, use_triplets=False)\n",
    "train_ds, val_ds = train_test_split_stratified(train_val_ds, test_size=0.2)\n",
    "test_ds = KIDataset(data_processor=processor, train=False, bundle_as_trials=True, use_triplets=False)\n",
    "\n",
    "# Binarize dataset after split to make sure split is stratified w.r.t all three classes\n",
    "if BINARY_CLF:\n",
    "    for ds in [train_ds, val_ds, test_ds]:\n",
    "        binarize(ds)\n",
    "\n",
    "# Initialize Dataloaders\n",
    "train_dl = DataLoader(train_ds,\n",
    "                      batch_size=BATCH_SIZE_TRIALS,\n",
    "                      sampler=ImbalancedDatasetSampler(train_ds, callback_get_label=lambda item: item.y))\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE_TRIALS)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE_TRIALS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Freeze InceptionTime and train transformer classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Use the best model in terms of validation loss\n",
    "inception_time = LitInceptionTimeModel.load_from_checkpoint(checkpoint_path.joinpath('epoch=193-step=2134.ckpt'))\n",
    "# Freeze parameters of the encoder\n",
    "inception_time.freeze()\n",
    "\n",
    "# Initialize Classifier\n",
    "clf = TransformerClassifier(in_features=inception_time.out_dim, **transformer_config)\n",
    "\n",
    "# Initialize lit time series classifier\n",
    "model = LitTimeSeriesClassifier(encoder=inception_time, decoder=clf, feature_dim=inception_time.out_dim, lr=1e-5,\n",
    "                                wd=1e-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\hejpa\\Anaconda3\\envs\\eyetrackpdc\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:613: UserWarning: Checkpoint directory C:\\Users\\hejpa\\Documents\\GitHub\\eye-track-pdc\\checkpoint exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                  | Params\n",
      "--------------------------------------------------\n",
      "0 | encoder | LitInceptionTimeModel | 1.2 M \n",
      "1 | decoder | TransformerClassifier | 269 K \n",
      "2 | loss_fn | BCEWithLogitsLoss     | 0     \n",
      "--------------------------------------------------\n",
      "269 K     Trainable params\n",
      "1.2 M     Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.693     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9df15c2fa40a45dfbd68c15a64e506dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hejpa\\Anaconda3\\envs\\eyetrackpdc\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "C:\\Users\\hejpa\\Anaconda3\\envs\\eyetrackpdc\\lib\\site-packages\\torch\\nn\\modules\\conv.py:310: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Convolution.cpp:896.)\n",
      "  self.padding, self.dilation, self.groups)\n",
      "C:\\Users\\hejpa\\Anaconda3\\envs\\eyetrackpdc\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  return trainer_fn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator='auto',\n",
    "                  max_epochs=500,\n",
    "                  logger=TensorBoardLogger(save_dir=log_path),\n",
    "                  callbacks=[LearningRateMonitor(),\n",
    "                             ModelCheckpoint(dirpath=checkpoint_path, monitor='val_loss', every_n_epochs=1)],\n",
    "                  log_every_n_steps=1)\n",
    "\n",
    "# Train the joint classifier\n",
    "trainer.fit(model, train_dl, val_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}