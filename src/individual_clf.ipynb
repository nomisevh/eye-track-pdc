{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset.individual import IndividualTrialDataset\n",
    "from dataset.ki import KIDataset\n",
    "from dataset.triplet import TripletSegmentDataset\n",
    "from models.classifier import IndividualClassifier\n",
    "from models.inception import InceptionTimeModel\n",
    "from train.inceptiontime import train_inception_time\n",
    "from train.transformer import train_transformer\n",
    "from utils.const import SEED\n",
    "from utils.data import PadCollate\n",
    "from utils.misc import set_random_state\n",
    "from utils.path import checkpoints_path as MODELS_PATH\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "torch.set_default_dtype(torch.float)\n",
    "DEVICE = 'cuda'\n",
    "INCLUDE_PDON_TF = True\n",
    "INCLUDE_PDON_SEGM = True\n",
    "BINARY_CLF = True\n",
    "N_EPOCHS = 400\n",
    "N_EPOCHS_CLF = 100\n",
    "EMBEDDER_CHKPT_FPATH = os.path.join(MODELS_PATH, f'inception_time{\"_pdon\" if INCLUDE_PDON_SEGM else \"\"}.pth')\n",
    "CLF_CHKPT_FPATH = os.path.join(MODELS_PATH, f'linear_clf{\"_pdon\" if INCLUDE_PDON_SEGM else \"\"}.pth')\n",
    "IND_CLF_CHKPT_FPATH = os.path.join(MODELS_PATH, f'ind_clf{\"_pdon\" if INCLUDE_PDON_SEGM else \"\"}.pth')\n",
    "TEST_CLF = False\n",
    "set_random_state(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset/Dataloader Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize Datasets\n",
    "ds_segm_train = KIDataset(train=True, which='segments', config='ki_auto', ki_data_dirname='KI',\n",
    "                          data_sources=['HC', 'PD_OFF', 'PD_ON'] if INCLUDE_PDON_SEGM else ['HC', 'PD_OFF'])\n",
    "ds_segm_test = KIDataset(train=False, which='segments', config='ki_auto', ki_data_dirname='KI',\n",
    "                         data_sources=['HC', 'PD_OFF', 'PD_ON'])\n",
    "# Dataloader\n",
    "dl_segm_train = DataLoader(TripletSegmentDataset(ds_segm_train, binary_clf=BINARY_CLF), batch_size=128, shuffle=True,\n",
    "                           pin_memory=True)\n",
    "dl_segm_test = DataLoader(TripletSegmentDataset(ds_segm_test, binary_clf=BINARY_CLF), batch_size=128, shuffle=False,\n",
    "                          pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## InceptionTime Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize Embedder\n",
    "embedder = InceptionTimeModel(bottleneck_channels=0,\n",
    "                              in_channels=4,\n",
    "                              kernel_sizes=65,\n",
    "                              num_blocks=3,\n",
    "                              num_pred_classes=32,\n",
    "                              out_channels=64,\n",
    "                              use_residuals='default')\n",
    "embedder = embedder.to(DEVICE)\n",
    "\n",
    "# Initialize Classifier\n",
    "clf = nn.Sequential(\n",
    "    nn.BatchNorm1d(embedder.out_dim),\n",
    "    nn.Linear(embedder.out_dim, 10),\n",
    "    nn.SELU(inplace=True),\n",
    "    nn.Linear(10, 2),\n",
    ")\n",
    "clf = clf.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "segm_optim = torch.optim.AdamW(embedder.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "segm_optim.add_param_group({\n",
    "    'params': clf.parameters(),\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-2\n",
    "})\n",
    "segm_optim_sched = torch.optim.lr_scheduler.SequentialLR(\n",
    "    segm_optim,\n",
    "    schedulers=[\n",
    "        torch.optim.lr_scheduler.LinearLR(segm_optim, total_iters=N_EPOCHS // 20),\n",
    "        torch.optim.lr_scheduler.CosineAnnealingLR(segm_optim, T_max=N_EPOCHS - N_EPOCHS // 20),\n",
    "    ],\n",
    "    milestones=[N_EPOCHS // 20]\n",
    ")\n",
    "\n",
    "# Criteria\n",
    "bce_crit = nn.BCEWithLogitsLoss()\n",
    "triplet_crit = nn.TripletMarginLoss(margin=1.0, p=2, swap=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(EMBEDDER_CHKPT_FPATH):\n",
    "    lt, lv, at, av = train_inception_time(embedder, clf, N_EPOCHS, dl_segm_train, dl_segm_test, DEVICE, segm_optim,\n",
    "                                          segm_optim_sched, bce_crit, triplet_crit)\n",
    "\n",
    "    # Save checkpoints\n",
    "    torch.save(embedder, EMBEDDER_CHKPT_FPATH)\n",
    "    torch.save(clf, CLF_CHKPT_FPATH)\n",
    "\n",
    "    # Plots\n",
    "    plt.plot(lt, label='loss train')\n",
    "    plt.plot(lv, label='loss test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.plot(at, label='acc train')\n",
    "    plt.plot(av, label='acc test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    #     embedder = torch.load(EMBEDDER_CHKPT_FPATH).to(DEVICE).eval()\n",
    "    ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Individual Classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datasets and Dataloader Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize Datasets\n",
    "ds_trial_train = KIDataset(train=True, which='trials', config='ki_auto', ki_data_dirname='KI',\n",
    "                           data_sources=['HC', 'PD_OFF', 'PD_ON'] if INCLUDE_PDON_TF else ['HC', 'PD_OFF'])\n",
    "ds_trial_test = KIDataset(train=False, which='trials', config='ki_auto', ki_data_dirname='KI',\n",
    "                          data_sources=['HC', 'PD_OFF', 'PD_ON'])\n",
    "\n",
    "# Dataloaders\n",
    "dl_trial_train = DataLoader(IndividualTrialDataset(ds_trial_train), batch_size=16, shuffle=True, pin_memory=True,\n",
    "                            drop_last=True, collate_fn=PadCollate(dim=0))\n",
    "dl_trial_test = DataLoader(IndividualTrialDataset(ds_trial_test), batch_size=16, shuffle=False, pin_memory=True,\n",
    "                           collate_fn=PadCollate(dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Freeze Embedder\n",
    "embedder_re = nn.Sequential(\n",
    "    Rearrange('b n l d -> (b n) d l'),\n",
    "    embedder,\n",
    ").to(DEVICE).eval()\n",
    "for p in embedder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "\n",
    "# Weight Initializer\n",
    "def init_weights(module: nn.Module):\n",
    "    if isinstance(module, nn.Embedding):\n",
    "        module.weight.data.normal_(mean=0.0, std=1.0)\n",
    "        if module.padding_idx is not None:\n",
    "            module.weight.data[module.padding_idx].zero_()\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        module.bias.data.zero_()\n",
    "        module.weight.data.fill_(1.0)\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        module.bias.data.zero_()\n",
    "        module.weight.data.normal_(mean=0.0, std=0.1)\n",
    "\n",
    "\n",
    "# Initialize Transformer (Classifier)\n",
    "ind_clf = IndividualClassifier(in_features=32, d_model=128, nhead=4, num_layers=2, dim_feedforward=256,\n",
    "                               batch_first=True, dropout=0.3, n_classes=2 if BINARY_CLF else 3)\n",
    "ind_clf.apply(init_weights)\n",
    "ind_clf = ind_clf.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "trial_optim = torch.optim.AdamW(ind_clf.parameters(), lr=1e-5, weight_decay=1e-1)\n",
    "# segm_optim_sched = torch.optim.lr_scheduler.CosineAnnealingLR(trial_optim, T_max=N_EPOCHS_CLF)\n",
    "trial_optim_sched = torch.optim.lr_scheduler.SequentialLR(\n",
    "    trial_optim,\n",
    "    schedulers=[\n",
    "        torch.optim.lr_scheduler.LinearLR(trial_optim, total_iters=N_EPOCHS_CLF // 20),\n",
    "        torch.optim.lr_scheduler.CosineAnnealingLR(trial_optim, T_max=N_EPOCHS_CLF - N_EPOCHS_CLF // 20),\n",
    "    ],\n",
    "    milestones=[N_EPOCHS_CLF // 20]\n",
    ")\n",
    "\n",
    "# Criteria\n",
    "bce_crit = nn.BCEWithLogitsLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lt, lv, at, av = train_transformer(embedder_re, ind_clf, N_EPOCHS_CLF, dl_trial_train, dl_trial_test, DEVICE,\n",
    "                                   trial_optim, trial_optim_sched, bce_crit)\n",
    "\n",
    "torch.save(ind_clf, IND_CLF_CHKPT_FPATH)\n",
    "\n",
    "# Plots\n",
    "plt.plot(lt, label='loss train')\n",
    "plt.plot(lv, label='loss test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(at, label='acc train')\n",
    "plt.plot(av, label='acc test')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}